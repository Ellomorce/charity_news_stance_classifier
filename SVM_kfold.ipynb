{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC \n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define File Path\n",
    "vec20avg_path = \"./vec_data/vec20_avg.npz\"\n",
    "vec25avg_path = \"./vec_data/vec25_avg.npz\"\n",
    "vec30avg_path = \"./vec_data/vec30_avg.npz\"\n",
    "vec35avg_path = \"./vec_data/vec35_avg.npz\"\n",
    "vec20sum_path = \"./vec_data/vec20_sum.npz\"\n",
    "vec20sum_path = \"./vec_data/vec20_sum.npz\"\n",
    "vec25sum_path = \"./vec_data/vec25_sum.npz\"\n",
    "vec30sum_path = \"./vec_data/vec30_sum.npz\"\n",
    "vec35sum_path = \"./vec_data/vec35_sum.npz\"\n",
    "# freq_stance_labels = \"./vec_data/freq_stance_labels.npz\"\n",
    "# oh_stance_labels = \"./vec_data/oh_stance_labels.npz\"\n",
    "le_stance_labels = \"./vec_data/le_stance_labels.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz_file(filepath):\n",
    "    # Load the numpy array from the .npz file\n",
    "    with np.load(filepath, allow_pickle=True) as data:\n",
    "        for key in data.keys():\n",
    "            arr = data[key]\n",
    "            break\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec20avg = load_npz_file(vec20avg_path)\n",
    "vec25avg = load_npz_file(vec25avg_path)\n",
    "vec30avg = load_npz_file(vec30avg_path)\n",
    "vec35avg = load_npz_file(vec35avg_path)\n",
    "vec20sum = load_npz_file(vec20sum_path)\n",
    "vec20sum = load_npz_file(vec20sum_path)\n",
    "vec25sum = load_npz_file(vec25sum_path)\n",
    "vec30sum = load_npz_file(vec30sum_path)\n",
    "vec35sum = load_npz_file(vec35sum_path)\n",
    "# freq_label = load_npz_file(freq_stance_labels)\n",
    "# oh_label = load_npz_file(oh_stance_labels)\n",
    "le_label = load_npz_file(le_stance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指派實際要使用的Data與Label\n",
    "# data = vec30sum\n",
    "# data = vec30avg\n",
    "# data = vec20sum\n",
    "data = vec20avg\n",
    "# data = vec25sum\n",
    "# data = vec25avg\n",
    "# data = vec35sum\n",
    "# data = vec35avg\n",
    "# label = np.argmax(oh_label, axis=1)\n",
    "# label = oh_label\n",
    "# label = freq_label\n",
    "label = le_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 1, 300)\n",
      "(445,)\n",
      "[0 1 2 3]\n",
      "(array([0, 1, 2, 3]), array([ 11, 201,  74, 159], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)\n",
    "print(np.unique(label))\n",
    "print(np.unique(label, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation using Oversampling\n",
    "# Define the oversampling ratio for each class\n",
    "# ratio0 = {0: 11, 1: 201, 2: 74, 3: 159}\n",
    "# ratio1 = {0: 24, 1: 201, 2: 78, 3: 168}\n",
    "# ratio2 = {0: 53, 1: 201, 2: 89, 3: 191}\n",
    "# ratio3 = {0: 86, 1: 201, 2: 115, 3: 172}\n",
    "# ratio4 = {0: 144, 1: 201, 2: 179, 3: 194}\n",
    "oversample_ratio = {0: 150, 1: 201, 2: 175, 3: 183}\n",
    "# Initialize the oversampler\n",
    "oversampler = RandomOverSampler(sampling_strategy=oversample_ratio)\n",
    "# Reshape your data to a 2D matrix of shape (n_samples, n_features)\n",
    "X = data.reshape(-1, 300)\n",
    "# Apply oversampling to X and y\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, label)\n",
    "# Reshape X back to its original shape\n",
    "# X_resampled = X_resampled.reshape(-1, 1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio = list(oversample_ratio.values())\n",
    "# ratio_scale = [round(ratio[0]/sum(ratio),2), round(ratio[1]/sum(ratio),2), round(ratio[2]/sum(ratio),2), round(ratio[3]/sum(ratio),2)]\n",
    "# print(ratio_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_resampled.shape)\n",
    "# print(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_resampled.shape)\n",
    "# print(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for k-fold cross-validation\n",
    "num_folds = 5\n",
    "# Initialize the k-fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# SVC parameters\n",
    "kernels = list(['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "c_optins = list([1, 5, 20, 25, 30, 35, 40, 45, 50])\n",
    "gammas = list([0.01, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "\n",
    "# Metrics reocrds\n",
    "model_ac_list = []\n",
    "model_pc_list = []\n",
    "model_rc_list = []\n",
    "model_f1_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "{'C': 5, 'gamma': 0.8, 'kernel': 'rbf'}\n",
      "Fold 2\n",
      "{'C': 5, 'gamma': 0.8, 'kernel': 'rbf'}\n",
      "Fold 3\n",
      "{'C': 1, 'gamma': 0.7, 'kernel': 'rbf'}\n",
      "Fold 4\n",
      "{'C': 5, 'gamma': 0.8, 'kernel': 'rbf'}\n",
      "Fold 5\n",
      "{'C': 20, 'gamma': 0.4, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_resampled, y_resampled)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    X_train_fold = X_resampled[train_idx]\n",
    "    y_train_fold = y_resampled[train_idx]\n",
    "    X_val_fold = X_resampled[val_idx]\n",
    "    y_val_fold = y_resampled[val_idx]\n",
    "\n",
    "    grid_clf = SVC()\n",
    "    param_grid = dict(kernel=kernels, C=c_optins, gamma=gammas)\n",
    "    grid = GridSearchCV(grid_clf, param_grid, cv=10, n_jobs=-1)\n",
    "    grid.fit(X_train_fold, y_train_fold)\n",
    "    best = grid.best_params_\n",
    "    print(best)\n",
    "\n",
    "    clf = SVC(C=best['C'], gamma=best['gamma'], kernel=best['kernel']) \n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = clf.predict(X_val_fold)\n",
    "\n",
    "    ac = accuracy_score(y_val_fold, y_pred)\n",
    "    pc = precision_score(y_pred, y_val_fold, average='macro')\n",
    "    rc = recall_score(y_pred, y_val_fold, average='macro')\n",
    "    f1 = f1_score(y_pred, y_val_fold, average='macro')\n",
    "    model_ac_list.append(ac)\n",
    "    model_pc_list.append(pc)\n",
    "    model_rc_list.append(rc)\n",
    "    model_f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_f1_list)\n",
    "# print(model_ac_list)\n",
    "# print(model_pc_list)\n",
    "# print(model_rc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_ac = sum(model_ac_list)/len(model_ac_list)\n",
    "Avg_pc = sum(model_pc_list)/len(model_pc_list)\n",
    "Avg_rc = sum(model_rc_list)/len(model_rc_list)\n",
    "Avg_f1 = sum(model_f1_list)/len(model_f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Model Accuracy: 93.09%\n",
      "Avg Model Precision: 93.54%\n",
      "Avg Model Recall: 93.76%\n",
      "Avg Model F1-score: 93.52%\n"
     ]
    }
   ],
   "source": [
    "print('Avg Model Accuracy: {:.2%}'.format(Avg_ac))\n",
    "print('Avg Model Precision: {:.2%}'.format(Avg_pc))\n",
    "print('Avg Model Recall: {:.2%}'.format(Avg_rc))\n",
    "print('Avg Model F1-score: {:.2%}'.format(Avg_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
