{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import spacy\n",
    "import pytextrank  # We're not going to execute this at home.\n",
    "# import pprint\n",
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Function\n",
    "def Tfidf(seg_list:list, top_k:int):\n",
    "    vectorizer = CountVectorizer() # 建立 CountVectorizer 物件\n",
    "    word_count = vectorizer.fit_transform(seg_list) # 將 text 轉成詞頻矩陣\n",
    "    tfidf_transformer = TfidfTransformer() # 建立 TfidfTransformer 物件\n",
    "    tfidf_matrix = tfidf_transformer.fit_transform(word_count) # 將詞頻矩陣轉換成 TF-IDF 矩陣\n",
    "    words = vectorizer.get_feature_names() # 取得詞彙表\n",
    "    tfidf_values = tfidf_matrix.toarray()[0] # 取得每個詞彙的 TF-IDF 值\n",
    "    sorted_index = np.argsort(tfidf_values)[::-1] # 取得排序後的索引位置\n",
    "    tfidf_keywords = [words[i] for i in sorted_index[:top_k]] # 取得排名前 K位 的關鍵字\n",
    "    return tfidf_keywords\n",
    "\n",
    "#TextRank Function\n",
    "def Txtrank(seg_list, top_k:int):\n",
    "    nlp = spacy.load('zh_core_web_sm')\n",
    "    nlp.add_pipe(\"textrank\")\n",
    "    doc = nlp(seg_list)\n",
    "    textrank_keywords = []\n",
    "    for p in doc._.phrases:\n",
    "        if len(textrank_keywords) >= top_k:\n",
    "            break\n",
    "        textrank_keywords.append(p.text)\n",
    "    return(textrank_keywords)\n",
    "\n",
    "#LDA Function\n",
    "\n",
    "def Lda(seg_list:list, Num_topics:int, Num_keywords:int, Max_iter:int):\n",
    "    vectorizer = CountVectorizer() # 建立CountVectorizer物件\n",
    "    X = vectorizer.fit_transform(seg_list) # 使用CountVectorizer物件將文本轉換成詞頻矩陣\n",
    "    lda = LatentDirichletAllocation(n_components=Num_topics, max_iter=Max_iter)\n",
    "    lda.fit_transform(X)\n",
    "    for topic_idx, topic in enumerate(lda.components_): # 取出每個主題的關鍵字\n",
    "        top_keyword_idxs = topic.argsort()[:-Num_keywords-1:-1]\n",
    "        top_keywords = [vectorizer.get_feature_names()[idx] for idx in top_keyword_idxs]\n",
    "    return top_keywords\n",
    "\n",
    "#以下檢驗準確率使用\n",
    "# Accuracy = （TP+TN） / （TP+TN+FP+FN）\n",
    "# Precision = TP /（TP+FP）\n",
    "# Recall = TP /（TP+FN）\n",
    "# extracted_list = TP + FP\n",
    "# valid_list = TP + FN\n",
    "# TP = set(extracted_list).intersection(set(valid_list))\n",
    "# FP = set(extracted_list).difference(set(valid_list))\n",
    "# FN = set(valid_list).difference(set(extracted_list))\n",
    "# TP+FP+FN = set(extracted_list).union(set(valid_list))\n",
    "# TN = ?????\n",
    "#\n",
    "# GPT算法\n",
    "# 這裡用來驗證關鍵字提取準確率的方式是：準確率 = (交集中的關鍵字數 / 驗證關鍵字數) × 100%\n",
    "# 其中，交集中的關鍵字數是指從文件中提取的關鍵字列表和驗證關鍵字列表的交集中包含的關鍵字數量。\n",
    "\n",
    "def accuracy_gpt(extracted_list:list, valid_list:list):\n",
    "    accuracy_results = []\n",
    "    for i in range(len(extracted_list)):\n",
    "        y_pred = extracted_list[i]\n",
    "        y_true = valid_list[i]\n",
    "        intersection = set(y_pred).intersection(set(y_true)) # 算出 TP\n",
    "        accuracy = len(intersection) / len(y_true)  # TP / TP + FN, GPT沒有把FP放進分母\n",
    "        accuracy_results.append(round(accuracy, 4)) #準確率僅顯示至小數點後四位\n",
    "    return accuracy_results\n",
    "#\n",
    "def accuracy_mine(extracted_list:list, valid_list:list):\n",
    "    accuracy_results = []\n",
    "    for i in range(len(extracted_list)):\n",
    "        y_pred = extracted_list[i]\n",
    "        y_true = valid_list[i]\n",
    "        intersection = set(y_pred).intersection(set(y_true)) # 算出 TP\n",
    "        accuracy = len(intersection) / len(set(y_pred).union(set(y_true)))  # TP / TP + FN + FP\n",
    "        accuracy_results.append(round(accuracy, 4)) #準確率僅顯示至小數點後四位\n",
    "    return accuracy_results\n",
    "#\n",
    "def precision_mine(extracted_list:list, valid_list:list):\n",
    "    precision_results = []\n",
    "    for i in range(len(extracted_list)):\n",
    "        y_pred = extracted_list[i]\n",
    "        y_true = valid_list[i]\n",
    "        intersection = set(y_pred).intersection(set(y_true)) # 算出 TP\n",
    "        precision = len(intersection) / len(y_pred) # TP / TP + FP, 這邊應該是沒有問題的\n",
    "        precision_results.append(round(precision, 4)) #精確率僅顯示至小數點後四位\n",
    "    return precision_results\n",
    "#\n",
    "def recall_mine(extracted_list:list, valid_list:list):\n",
    "    recall_results = []\n",
    "    for i in range(len(extracted_list)):\n",
    "        y_pred = extracted_list[i]\n",
    "        y_true = valid_list[i]\n",
    "        intersection = set(y_pred).intersection(set(y_true)) # 算出 TP\n",
    "        recall = len(intersection) / len(y_true) # TP / TP + FN, 這邊應該是沒有問題的\n",
    "        recall_results.append(round(recall, 4))\n",
    "    return recall_results\n",
    "#\n",
    "def f1_score_mine(precision_results:list, recall_results:list):\n",
    "    f1_results = []\n",
    "    for i in range(len(precision_results)):\n",
    "        pc = precision_results[i]\n",
    "        rc = recall_results[i]\n",
    "        if pc + rc == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * ((pc * rc) / (pc + rc))\n",
    "        f1_results.append(round(f1, 4))\n",
    "    return f1_results\n",
    "\n",
    "def fbeta_score(precision_results:list, recall_results:list, beta:float):\n",
    "    fbeta_results = []\n",
    "    for i in range(len(precision_results)):\n",
    "        pc = precision_results[i]\n",
    "        rc = recall_results[i]\n",
    "        if pc + rc == 0:\n",
    "            fbeta = 0\n",
    "        else:\n",
    "            fbeta = ((1+beta**2) * pc * rc) / ((pc * beta**2) + rc)\n",
    "        fbeta_results.append(round(fbeta, 4))\n",
    "    return fbeta_results\n",
    "\n",
    "# 以上使用的是集體檢測預測詞命中驗證詞的狀況，以下是採取將預測詞一一取出驗證真假，並填寫1/0的方法。\n",
    "# def calculate_roc_auc(extracted_list:list, valid_list:list):\n",
    "#     # 將預測詞轉換為二元陣列，其中1表示該詞存在於真正的答案中，0表示不存在\n",
    "#     y_true = [1 if keyword in valid_list else 0 for keyword in extracted_list]\n",
    "#     y_scores = [0 if keyword in valid_list else 1 for keyword in extracted_list]\n",
    "#     # 計算ROC Curve下的FPR和TPR以及閾值\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "#     # 計算ROC Curve下的AUC\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "#     return roc_auc\n",
    "\n",
    "# def calculate_pr_auc(extracted_list:list, valid_list:list):\n",
    "#     # 將預測詞轉換為二元陣列，其中1表示該詞存在於真正的答案中，0表示不存在\n",
    "#     y_true = [1 if keyword in valid_list else 0 for keyword in extracted_list]\n",
    "#     y_scores = [0 if keyword in valid_list else 1 for keyword in extracted_list]\n",
    "#     # 計算Precision-Recall Curve下的precision和recall以及閾值\n",
    "#     precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "#     # 計算Precision-Recall Curve下的AUC\n",
    "#     pr_auc = auc(recall, precision)\n",
    "#     return pr_auc\n",
    "\n",
    "# def calculate_precision(extracted_list:list, valid_list:list):\n",
    "#     # 將預測詞轉換為二元陣列，其中1表示該詞存在於真正的答案中，0表示不存在\n",
    "#     y_true = [1 if keyword in valid_list else 0 for keyword in extracted_list]\n",
    "#     y_pred = [1 if keyword in extracted_list else 0 for keyword in valid_list]\n",
    "#     # 計算Precision\n",
    "#     precision = precision_score(y_true, y_pred)\n",
    "#     return precision\n",
    "\n",
    "# def calculate_recall(extracted_list:list, valid_list:list):\n",
    "#     # 將預測詞轉換為二元陣列，其中1表示該詞存在於真正的答案中，0表示不存在\n",
    "#     y_true = [1 if keyword in valid_list else 0 for keyword in extracted_list]\n",
    "#     y_pred = [1 if keyword in extracted_list else 0 for keyword in valid_list]\n",
    "#     # 計算Recall\n",
    "#     recall = recall_score(y_true, y_pred)\n",
    "#     return recall\n",
    "\n",
    "# def calculate_f1_score(extracted_list:list, valid_list:list):\n",
    "#     # 將預測詞轉換為二元陣列，其中1表示該詞存在於真正的答案中，0表示不存在\n",
    "#     y_true = [1 if keyword in valid_list else 0 for keyword in extracted_list]\n",
    "#     y_pred = [1 if keyword in extracted_list else 0 for keyword in valid_list]\n",
    "#     # 計算F1-Score\n",
    "#     f1_score = f1_score(y_true, y_pred)\n",
    "#     return f1_score\n",
    "\n",
    "#以上用來跑多個K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_topic = pd.read_csv('taiwan_charity_news_topic.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Foreign_key</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Media</th>\n",
       "      <th>Content</th>\n",
       "      <th>Topic_test</th>\n",
       "      <th>Seg_list</th>\n",
       "      <th>News_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>2020/10/22</td>\n",
       "      <td>視力僅剩0.3，愛盲助其考證照、工作、帶大4子長大</td>\n",
       "      <td>Chinatimes</td>\n",
       "      <td>視障媽媽林佳臻，在視障、單親、低收入戶等窘迫條件下，15年來，不但一手撐起整個家、帶大四個孩...</td>\n",
       "      <td>Visually_impaired_mom</td>\n",
       "      <td>視障 媽媽 林佳臻 視障 單親 低收入戶 窘迫 條件 下 15 年 來 撐起 整 個 家 帶...</td>\n",
       "      <td>愛盲, 服務, 視障, 媽媽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>2020/10/22</td>\n",
       "      <td>視力0.3的「超能力」。她靠1把掃把，養活4子女。</td>\n",
       "      <td>United_Daily_News</td>\n",
       "      <td>「天下的媽媽都是一樣的」，誰說視障女性無法勝任媽媽的角色？\\n愛盲基金會表示，基金會成立近3...</td>\n",
       "      <td>Visually_impaired_mom</td>\n",
       "      <td>天下 媽媽 一樣 說 視障 女性 勝任 媽媽 角色 愛盲 基金會 表示 基金會 成立 近 3...</td>\n",
       "      <td>愛盲, 服務, 視障, 媽媽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>2020/10/22</td>\n",
       "      <td>視力僅剩0.3，愛盲助其考證照、工作、帶大4子長大。</td>\n",
       "      <td>Commercial_Times</td>\n",
       "      <td>視障媽媽林佳臻，在視障、單親、低收入戶等窘迫條件下，15年來，不但一手撐起整個家、帶大四個孩...</td>\n",
       "      <td>Visually_impaired_mom</td>\n",
       "      <td>視障 媽媽 林佳臻 視障 單親 低收入戶 窘迫 條件 下 15 年 來 撐起 整 個 家 帶...</td>\n",
       "      <td>愛盲, 服務, 視障, 媽媽</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Foreign_key        Date                       Title              Media  \\\n",
       "0           96  2020/10/22   視力僅剩0.3，愛盲助其考證照、工作、帶大4子長大         Chinatimes   \n",
       "1           97  2020/10/22   視力0.3的「超能力」。她靠1把掃把，養活4子女。  United_Daily_News   \n",
       "2           98  2020/10/22  視力僅剩0.3，愛盲助其考證照、工作、帶大4子長大。   Commercial_Times   \n",
       "\n",
       "                                             Content             Topic_test  \\\n",
       "0  視障媽媽林佳臻，在視障、單親、低收入戶等窘迫條件下，15年來，不但一手撐起整個家、帶大四個孩...  Visually_impaired_mom   \n",
       "1  「天下的媽媽都是一樣的」，誰說視障女性無法勝任媽媽的角色？\\n愛盲基金會表示，基金會成立近3...  Visually_impaired_mom   \n",
       "2  視障媽媽林佳臻，在視障、單親、低收入戶等窘迫條件下，15年來，不但一手撐起整個家、帶大四個孩...  Visually_impaired_mom   \n",
       "\n",
       "                                            Seg_list       News_tags  \n",
       "0  視障 媽媽 林佳臻 視障 單親 低收入戶 窘迫 條件 下 15 年 來 撐起 整 個 家 帶...  愛盲, 服務, 視障, 媽媽  \n",
       "1  天下 媽媽 一樣 說 視障 女性 勝任 媽媽 角色 愛盲 基金會 表示 基金會 成立 近 3...  愛盲, 服務, 視障, 媽媽  \n",
       "2  視障 媽媽 林佳臻 視障 單親 低收入戶 窘迫 條件 下 15 年 來 撐起 整 個 家 帶...  愛盲, 服務, 視障, 媽媽  "
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_topic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs = []\n",
    "\n",
    "for seg in data_topic['Seg_list']:\n",
    "    sg = seg.split(' ')\n",
    "    segs.append(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for tag in data_topic['News_tags']:\n",
    "    tag = tag.replace(\",\", '').split(' ')\n",
    "    tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_value = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_list = []\n",
    "for sg in segs:\n",
    "    x= Tfidf(sg, K_value)\n",
    "    tfidf_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tfidf_list[0])\n",
    "# print(len(tfidf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtrank_list =[]\n",
    "for sg in segs:\n",
    "    sgj = \" \".join(sg)\n",
    "    y= Txtrank(sgj, K_value)\n",
    "    txtrank_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今年', '台灣', '單親', '林佳臻', '0', '12 年', '15 年', '20', '3', '500', '6', '87％', '三', '三成', '六', '四', '第二']\n"
     ]
    }
   ],
   "source": [
    "print(txtrank_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_list = []\n",
    "for sg in segs:\n",
    "    z= Lda(sg, 1, K_value, 50)\n",
    "    lda_list.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lda_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic1_idx = [0, 1, 2, 3, 4]\n",
    "# Topic2_idx = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "# Topic3_idx = [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29]\n",
    "# Topic4_idx = [24, 25, 26, 27, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0541, 0.0541, 0.0541, 0.0541, 0.0541, 0.0811, 0.0811, 0.1111, 0.0811, 0.1111, 0.0811, 0.0811, 0.0811, 0.0233, 0.0465, 0.0233, 0.0476, 0.075, 0.0476, 0.0233, 0.0513, 0.0233, 0.0513, 0.0476, 0.025, 0.0833, 0.025, 0.025, 0.0789, 0.0732]\n",
      "[0.0571, 0.0571, 0.0571, 0.0571, 0.0571, 0.0857, 0.0857, 0.1143, 0.0857, 0.1143, 0.0857, 0.0857, 0.0857, 0.0286, 0.0571, 0.0286, 0.0571, 0.0857, 0.0571, 0.0286, 0.0571, 0.0286, 0.0571, 0.0571, 0.0286, 0.0857, 0.0286, 0.0286, 0.0857, 0.0857]\n",
      "[0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.8, 0.6, 0.8, 0.6, 0.6, 0.6, 0.1111, 0.2, 0.1111, 0.2222, 0.375, 0.2222, 0.1111, 0.3333, 0.1111, 0.3333, 0.2222, 0.1667, 0.75, 0.1667, 0.1667, 0.5, 0.3333]\n",
      "[0.1025, 0.1025, 0.1025, 0.1025, 0.1025, 0.15, 0.15, 0.2, 0.15, 0.2, 0.15, 0.15, 0.15, 0.0455, 0.0888, 0.0455, 0.0909, 0.1395, 0.0909, 0.0455, 0.0975, 0.0455, 0.0975, 0.0909, 0.0488, 0.1538, 0.0488, 0.0488, 0.1463, 0.1363]\n",
      "[0.1476, 0.1476, 0.1476, 0.1476, 0.1476, 0.2108, 0.2108, 0.2811, 0.2108, 0.2811, 0.2108, 0.2108, 0.2108, 0.0589, 0.113, 0.0589, 0.1176, 0.1839, 0.1176, 0.0589, 0.1339, 0.0589, 0.1339, 0.1176, 0.0671, 0.2216, 0.0671, 0.0671, 0.201, 0.1764]\n",
      "[0.196, 0.196, 0.196, 0.196, 0.196, 0.2727, 0.2727, 0.3637, 0.2727, 0.3637, 0.2727, 0.2727, 0.2727, 0.0705, 0.1333, 0.0705, 0.1408, 0.2239, 0.1408, 0.0705, 0.1694, 0.0705, 0.1694, 0.1408, 0.0848, 0.2941, 0.0848, 0.0848, 0.2542, 0.2112]\n",
      "[0.2416, 0.2416, 0.2416, 0.2416, 0.2416, 0.3283, 0.3283, 0.4378, 0.3283, 0.4378, 0.3283, 0.3283, 0.3283, 0.0795, 0.1487, 0.0795, 0.1588, 0.2559, 0.1588, 0.0795, 0.1999, 0.0795, 0.1999, 0.1588, 0.1001, 0.3625, 0.1001, 0.1001, 0.3, 0.2383]\n",
      "[0.2816, 0.2816, 0.2816, 0.2816, 0.2816, 0.375, 0.375, 0.5, 0.375, 0.5, 0.375, 0.375, 0.375, 0.0862, 0.16, 0.0862, 0.1724, 0.2804, 0.1724, 0.0862, 0.2246, 0.0862, 0.2246, 0.1724, 0.1124, 0.4225, 0.1124, 0.1124, 0.3371, 0.2586]\n"
     ]
    }
   ],
   "source": [
    "#TFIDF-Metrics\n",
    "TFIDF_acc = accuracy_mine(tfidf_list, tags)\n",
    "TFIDF_pc = precision_mine(tfidf_list, tags)\n",
    "TFIDF_rc = recall_mine(tfidf_list, tags)\n",
    "TFIDF_f1 = f1_score_mine(TFIDF_pc, TFIDF_rc)\n",
    "TFIDF_fb15 = fbeta_score(TFIDF_pc, TFIDF_rc, 1.5)\n",
    "TFIDF_fb20 = fbeta_score(TFIDF_pc, TFIDF_rc, 2.0)\n",
    "TFIDF_fb25 = fbeta_score(TFIDF_pc, TFIDF_rc, 2.5)\n",
    "TFIDF_fb30 = fbeta_score(TFIDF_pc, TFIDF_rc, 3.0)\n",
    "print(TFIDF_acc)\n",
    "print(TFIDF_pc)\n",
    "print(TFIDF_rc)\n",
    "print(TFIDF_f1)\n",
    "print(TFIDF_fb15)\n",
    "print(TFIDF_fb20)\n",
    "print(TFIDF_fb25)\n",
    "print(TFIDF_fb30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0263, 0.0278, 0.0345, 0.0278, 0.0, 0.0357, 0.0323, 0.0, 0.027, 0.0, 0.0417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0294]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0333, 0.037, 0.0476, 0.0357, 0.0, 0.05, 0.0435, 0.0, 0.0345, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0385]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111, 0.1, 0.1111, 0.1111, 0.0, 0.1111, 0.1111, 0.0, 0.1111, 0.0, 0.1111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111]\n",
      "[0, 0, 0, 0, 0, 0, 0.1176, 0, 0, 0, 0, 0, 0, 0.0512, 0.054, 0.0666, 0.054, 0, 0.069, 0.0625, 0, 0.0527, 0, 0.08, 0, 0, 0, 0, 0, 0.0572]\n",
      "[0, 0, 0, 0, 0, 0, 0.1398, 0, 0, 0, 0, 0, 0, 0.0646, 0.0656, 0.0788, 0.0673, 0, 0.0807, 0.0752, 0, 0.066, 0, 0.0897, 0, 0, 0, 0, 0, 0.0703]\n",
      "[0, 0, 0, 0, 0, 0, 0.1562, 0, 0, 0, 0, 0, 0, 0.0757, 0.0746, 0.0877, 0.0781, 0, 0.0893, 0.0848, 0, 0.0769, 0, 0.0961, 0, 0, 0, 0, 0, 0.0807]\n",
      "[0, 0, 0, 0, 0, 0, 0.1676, 0, 0, 0, 0, 0, 0, 0.084, 0.081, 0.0938, 0.086, 0, 0.0951, 0.0915, 0, 0.0851, 0, 0.1003, 0, 0, 0, 0, 0, 0.0882]\n",
      "[0, 0, 0, 0, 0, 0, 0.1754, 0, 0, 0, 0, 0, 0, 0.0901, 0.0855, 0.098, 0.0917, 0, 0.099, 0.0962, 0, 0.0909, 0, 0.1031, 0, 0, 0, 0, 0, 0.0935]\n"
     ]
    }
   ],
   "source": [
    "# TextRank-Metrics\n",
    "TextRank_acc = accuracy_mine(txtrank_list, tags)\n",
    "TextRank_pc = precision_mine(txtrank_list, tags)\n",
    "TextRank_rc = recall_mine(txtrank_list, tags)\n",
    "TextRank_f1 = f1_score_mine(TextRank_pc, TextRank_rc)\n",
    "TextRank_fb15 = fbeta_score(TextRank_pc, TextRank_rc, 1.5)\n",
    "TextRank_fb20 = fbeta_score(TextRank_pc, TextRank_rc, 2.0)\n",
    "TextRank_fb25 = fbeta_score(TextRank_pc, TextRank_rc, 2.5)\n",
    "TextRank_fb30 = fbeta_score(TextRank_pc, TextRank_rc, 3.0)\n",
    "print(TextRank_acc)\n",
    "print(TextRank_pc)\n",
    "print(TextRank_rc)\n",
    "print(TextRank_f1)\n",
    "print(TextRank_fb15)\n",
    "print(TextRank_fb20)\n",
    "print(TextRank_fb25)\n",
    "print(TextRank_fb30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1143, 0.1143, 0.1143, 0.1143, 0.0833, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.2571, 0.25, 0.2571, 0.2571, 0.1622, 0.2571, 0.2222, 0.0789, 0.2571, 0.0789, 0.2222, 0.1714, 0.1143, 0.1714, 0.1714, 0.1081, 0.2222]\n",
      "[0.1143, 0.1143, 0.1143, 0.1143, 0.0857, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.2571, 0.2571, 0.2571, 0.2571, 0.1714, 0.2571, 0.2286, 0.0857, 0.2571, 0.0857, 0.2286, 0.1714, 0.1143, 0.1714, 0.1714, 0.1143, 0.2286]\n",
      "[1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 0.75, 1.0, 0.8889, 0.5, 1.0, 0.5, 0.8889, 1.0, 1.0, 1.0, 1.0, 0.6667, 0.8889]\n",
      "[0.2052, 0.2052, 0.2052, 0.2052, 0.1538, 0.2501, 0.2501, 0.2501, 0.2501, 0.2501, 0.2501, 0.2501, 0.2501, 0.409, 0.3999, 0.409, 0.409, 0.279, 0.409, 0.3637, 0.1463, 0.409, 0.1463, 0.3637, 0.2926, 0.2052, 0.2926, 0.2926, 0.1951, 0.3637]\n",
      "[0.2955, 0.2955, 0.2955, 0.2955, 0.2216, 0.3514, 0.3514, 0.3514, 0.3514, 0.3514, 0.3514, 0.3514, 0.3514, 0.5294, 0.5086, 0.5294, 0.5294, 0.3679, 0.5294, 0.4706, 0.201, 0.5294, 0.201, 0.4706, 0.402, 0.2955, 0.402, 0.402, 0.2681, 0.4706]\n",
      "[0.3922, 0.3922, 0.3922, 0.3922, 0.2941, 0.4546, 0.4546, 0.4546, 0.4546, 0.4546, 0.4546, 0.4546, 0.4546, 0.6338, 0.6, 0.6338, 0.6338, 0.4477, 0.6338, 0.5634, 0.2542, 0.6338, 0.2542, 0.5634, 0.5084, 0.3922, 0.5084, 0.5084, 0.339, 0.5634]\n",
      "[0.5634, 0.5634, 0.5634, 0.5634, 0.4225, 0.6251, 0.6251, 0.6251, 0.6251, 0.6251, 0.6251, 0.6251, 0.6251, 0.7758, 0.72, 0.7758, 0.7758, 0.5607, 0.7758, 0.6897, 0.3371, 0.7758, 0.3371, 0.6897, 0.6741, 0.5634, 0.6741, 0.6741, 0.4495, 0.6897]\n"
     ]
    }
   ],
   "source": [
    "# LDA-Metrics\n",
    "LDA_acc = accuracy_mine(lda_list, tags)\n",
    "LDA_pc = precision_mine(lda_list, tags)\n",
    "LDA_rc = recall_mine(lda_list, tags)\n",
    "LDA_f1 = f1_score_mine(LDA_pc, LDA_rc)\n",
    "LDA_fb15 = fbeta_score(LDA_pc, LDA_rc, 1.5)\n",
    "LDA_fb20 = fbeta_score(LDA_pc, LDA_rc, 2.0)\n",
    "LDA_fb25 = fbeta_score(LDA_pc, LDA_rc, 2.5)\n",
    "LDA_fb30 = fbeta_score(LDA_pc, LDA_rc, 3.0)\n",
    "print(LDA_acc)\n",
    "print(LDA_pc)\n",
    "print(LDA_rc)\n",
    "print(LDA_f1)\n",
    "print(LDA_fb15)\n",
    "print(LDA_fb20)\n",
    "print(LDA_fb30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96, 97, 98, 101, 107, 128, 129, 130, 131, 132, 133, 134, 135, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 256, 260, 262, 263, 264, 265, 270]\n",
      "['Visually_impaired_mom', 'Visually_impaired_mom', 'Visually_impaired_mom', 'Visually_impaired_mom', 'Visually_impaired_mom', 'Okmart_charity_event', 'Okmart_charity_event', 'Okmart_charity_event', 'Okmart_charity_event', 'Okmart_charity_event', 'Okmart_charity_event', 'Okmart_charity_event', 'Okmart_charity_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'life_rebuild_event', 'dark experience', 'dark experience', 'dark experience', 'dark experience', 'dark experience', 'life_rebuild_event']\n"
     ]
    }
   ],
   "source": [
    "Text_Num = data_topic['Foreign_key'].to_list()\n",
    "Topics = data_topic['Topic_test'].to_list()\n",
    "print(Text_Num)\n",
    "print(Topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metrics = {'Text_Num':data_topic['Foreign_key'], 'Topic':data_topic['Topic_test'], 'TFIDF_acc':TFIDF_acc, 'TFIDF_pc':TFIDF_pc, \n",
    "           'TFIDF_rc':TFIDF_rc, 'TFIDF_f1':TFIDF_f1, 'TFIDF_fb15': TFIDF_fb15, 'TFIDF_fb20':TFIDF_fb20, 'TFIDF_fb25':TFIDF_fb25, 'TFIDF_fb30':TFIDF_fb30, \n",
    "           'TextRank_acc':TextRank_acc, 'TextRank_pc':TextRank_pc, 'TextRank_rc':TextRank_rc, 'TextRank_f1':TextRank_f1, \n",
    "           'TextRank_fb15':TextRank_fb15, 'TextRank_fb20':TextRank_fb20, 'TextRank_fb25':TextRank_fb25, 'TextRank_fb30':TextRank_fb30,\n",
    "           'LDA_acc':LDA_acc, 'LDA_pc':LDA_pc, 'LDA_rc':LDA_rc, 'LDA_f1':LDA_f1, \n",
    "           'LDA_fb15':LDA_fb15, 'LDA_fb20':LDA_fb20, 'LDA_fb25':LDA_fb25, 'LDA_fb30':LDA_fb30}\n",
    "\n",
    "keyword_metrics = pd.DataFrame(data=Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_metrics.to_csv(f'keyword_metrics_k{K_value}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0541, 0.0571, 0.5, 0.1025, 0.1476, 0.196, 0.2416, 0.2816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1081, 0.1086, 0.95, 0.1949, 0.2807, 0.3726, 0.4592, 0.5352]\n",
      "['Visually_impaired_mom', 0.0541, 0.0571, 0.5, 0.1025, 0.1476, 0.196, 0.2416, 0.2816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1081, 0.1086, 0.95, 0.1949, 0.2807, 0.3726, 0.4592, 0.5352]\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# 篩選'Topic'為'Visually_impaired_mom'的行\n",
    "topic1 = keyword_metrics.loc[keyword_metrics['Topic'] == 'Visually_impaired_mom']\n",
    "# 計算各項目的算術平均數\n",
    "topic1_mean = round(topic1.iloc[:, 2:26].mean(numeric_only=True), 4).to_list()\n",
    "# 篩選'Topic'為'Okmart_charity_event'的行\n",
    "topic2 = keyword_metrics.loc[keyword_metrics['Topic'] == 'Okmart_charity_event']\n",
    "# 計算各項目的算術平均數\n",
    "topic2_mean = round(topic2.iloc[:, 2:26].mean(numeric_only=True), 4).to_list()\n",
    "# 篩選'Topic'為'life_rebuild_event'的行\n",
    "topic3 = keyword_metrics.loc[keyword_metrics['Topic'] == 'life_rebuild_event']\n",
    "# 計算各項目的算術平均數\n",
    "topic3_mean = round(topic3.iloc[:, 2:26].mean(numeric_only=True), 4).to_list()\n",
    "# 篩選'Topic'為'dark experience'的行\n",
    "topic4 = keyword_metrics.loc[keyword_metrics['Topic'] == 'dark experience']\n",
    "# 計算各項目的算術平均數\n",
    "topic4_mean = round(topic4.iloc[:, 2:26].mean(numeric_only=True), 4).to_list()\n",
    "\n",
    "# 製作列資料\n",
    "Line1 = ['Visually_impaired_mom'] + topic1_mean\n",
    "Line2 = ['Okmart_charity_event'] + topic2_mean\n",
    "Line3 = ['life_rebuild_event'] + topic3_mean\n",
    "Line4 = ['dark experience'] + topic4_mean\n",
    "\n",
    "print(topic1_mean)\n",
    "print(Line1)\n",
    "print(len(Line1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建Comparison DataFrame\n",
    "cols = [\n",
    "    'Topics', \n",
    "    'TFIDF_acc_avg', \n",
    "    'TFIDF_pc_avg', \n",
    "    'TFIDF_rc_avg', \n",
    "    'TFIDF_f1_avg', \n",
    "    'TFIDF_fb15_avg',\n",
    "    'TFIDF_fb20_avg',\n",
    "    'TFIDF_fb25_avg',\n",
    "    'TFIDF_fb30_avg',\n",
    "    'TextRank_acc_avg', \n",
    "    'TextRank_pc_avg', \n",
    "    'TextRank_rc_avg', \n",
    "    'TextRank_f1_avg', \n",
    "    'TextRank_fb15_avg',\n",
    "    'TextRank_fb20_avg',\n",
    "    'TextRank_fb25_avg',\n",
    "    'TextRank_fb30_avg',\n",
    "    'LDA_acc_avg', \n",
    "    'LDA_pc_avg', \n",
    "    'LDA_rc_avg', \n",
    "    'LDA_f1_avg',\n",
    "    'LDA_fb15_avg',\n",
    "    'LDA_fb20_avg',\n",
    "    'LDA_fb25_avg',\n",
    "    'LDA_fb30_avg']\n",
    "\n",
    "# 建立DF物件\n",
    "Comparison = pd.DataFrame(columns=cols)\n",
    "\n",
    "Comparison.loc[0] = Line1\n",
    "Comparison.loc[1] = Line2\n",
    "Comparison.loc[2] = Line3\n",
    "Comparison.loc[3] = Line4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>TFIDF_acc_avg</th>\n",
       "      <th>TFIDF_pc_avg</th>\n",
       "      <th>TFIDF_rc_avg</th>\n",
       "      <th>TFIDF_f1_avg</th>\n",
       "      <th>TFIDF_fb15_avg</th>\n",
       "      <th>TFIDF_fb20_avg</th>\n",
       "      <th>TFIDF_fb25_avg</th>\n",
       "      <th>TFIDF_fb30_avg</th>\n",
       "      <th>TextRank_acc_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>TextRank_fb25_avg</th>\n",
       "      <th>TextRank_fb30_avg</th>\n",
       "      <th>LDA_acc_avg</th>\n",
       "      <th>LDA_pc_avg</th>\n",
       "      <th>LDA_rc_avg</th>\n",
       "      <th>LDA_f1_avg</th>\n",
       "      <th>LDA_fb15_avg</th>\n",
       "      <th>LDA_fb20_avg</th>\n",
       "      <th>LDA_fb25_avg</th>\n",
       "      <th>LDA_fb30_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visually_impaired_mom</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.5352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Okmart_charity_event</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.6251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>life_rebuild_event</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.2238</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>0.4448</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.6586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dark experience</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.2194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.3539</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>0.6070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Topics  TFIDF_acc_avg  TFIDF_pc_avg  TFIDF_rc_avg  \\\n",
       "0  Visually_impaired_mom         0.0541        0.0571        0.5000   \n",
       "1   Okmart_charity_event         0.0886        0.0928        0.6500   \n",
       "2     life_rebuild_event         0.0444        0.0524        0.2238   \n",
       "3        dark experience         0.0474        0.0514        0.3500   \n",
       "\n",
       "   TFIDF_f1_avg  TFIDF_fb15_avg  TFIDF_fb20_avg  TFIDF_fb25_avg  \\\n",
       "0        0.1025          0.1476          0.1960          0.2416   \n",
       "1        0.1625          0.2284          0.2954          0.3557   \n",
       "2        0.0845          0.1108          0.1343          0.1531   \n",
       "3        0.0893          0.1248          0.1605          0.1926   \n",
       "\n",
       "   TFIDF_fb30_avg  TextRank_acc_avg  ...  TextRank_fb25_avg  \\\n",
       "0          0.2816            0.0000  ...             0.0000   \n",
       "1          0.4062            0.0078  ...             0.0210   \n",
       "2          0.1675            0.0235  ...             0.0671   \n",
       "3          0.2194            0.0000  ...             0.0000   \n",
       "\n",
       "   TextRank_fb30_avg  LDA_acc_avg  LDA_pc_avg  LDA_rc_avg  LDA_f1_avg  \\\n",
       "0             0.0000       0.1081      0.1086      0.9500      0.1949   \n",
       "1             0.0219       0.1429      0.1429      1.0000      0.2501   \n",
       "2             0.0707       0.2102      0.2143      0.8597      0.3423   \n",
       "3             0.0000       0.1473      0.1486      0.9333      0.2556   \n",
       "\n",
       "   LDA_fb15_avg  LDA_fb20_avg  LDA_fb25_avg  LDA_fb30_avg  \n",
       "0        0.2807        0.3726        0.4592        0.5352  \n",
       "1        0.3514        0.4546        0.5473        0.6251  \n",
       "2        0.4448        0.5346        0.6052        0.6586  \n",
       "3        0.3539        0.4513        0.5367        0.6070  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparison.to_csv(f'Comparisonk{K_value}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "#製作統計表格的表頭\n",
    "#Table to Pic\n",
    "# fig = go.Figure(data=[go.Table(\n",
    "#     header=dict(values=cols,\n",
    "#                 line_color='darkslategray',\n",
    "#                 fill_color='#C0C0C0',\n",
    "#                 align='center',\n",
    "#                 font=dict(color='#000000', size=12)),\n",
    "#     cells=dict(values=[Comparison['Topics'],\n",
    "#                        Comparison['TFIDF_acc_avg'], \n",
    "#                        Comparison['TFIDF_pc_avg'], \n",
    "#                        Comparison['TFIDF_rc_avg'], \n",
    "#                        Comparison['TFIDF_f1_avg'], \n",
    "#                        Comparison['TextRank_acc_avg'],\n",
    "#                        Comparison['TextRank_pc_avg'],\n",
    "#                        Comparison['TextRank_rc_avg'],\n",
    "#                        Comparison['TextRank_f1_avg'],\n",
    "#                        Comparison['LDA_acc_avg'],\n",
    "#                        Comparison['LDA_pc_avg'],\n",
    "#                        Comparison['LDA_rc_avg'],\n",
    "#                        Comparison['LDA_f1_avg'],\n",
    "#                        ],\n",
    "#                line_color='darkslategray',\n",
    "#                fill_color='#FFFFFF',\n",
    "#                align='center',\n",
    "#                font=dict(color='#000000', size=12)))\n",
    "# ])\n",
    "# fig.update_layout(height=140, width=1800, margin=dict(r=10, l=10, t=10, b=10))\n",
    "# fig.write_image(\"Keyword_Metrics_K_10.png\", scale=2)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "#製作統計表格的表頭 No acc\n",
    "#Table to Pic\n",
    "# fig = go.Figure(data=[go.Table(\n",
    "#     header=dict(values=no_acc,\n",
    "#                 line_color='darkslategray',\n",
    "#                 fill_color='#C0C0C0',\n",
    "#                 align='center',\n",
    "#                 font=dict(color='#000000', size=12)),\n",
    "#     cells=dict(values=[Comparison['Topics'],\n",
    "#                        Comparison['TFIDF_pc_avg'], \n",
    "#                        Comparison['TFIDF_rc_avg'], \n",
    "#                        Comparison['TFIDF_f1_avg'], \n",
    "#                        Comparison['TextRank_pc_avg'],\n",
    "#                        Comparison['TextRank_rc_avg'],\n",
    "#                        Comparison['TextRank_f1_avg'],\n",
    "#                        Comparison['LDA_pc_avg'],\n",
    "#                        Comparison['LDA_rc_avg'],\n",
    "#                        Comparison['LDA_f1_avg'],\n",
    "#                        ],\n",
    "#                line_color='darkslategray',\n",
    "#                fill_color='#FFFFFF',\n",
    "#                align='center',\n",
    "#                font=dict(color='#000000', size=12)))\n",
    "# ])\n",
    "# fig.update_layout(height=140, width=1400, margin=dict(r=10, l=10, t=10, b=10))\n",
    "# fig.write_image(\"Keyword_Metrics_K_15_noacc.png\", scale=2)\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
